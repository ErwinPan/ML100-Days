{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測\n",
    "***\n",
    "- 以下用鐵達尼預測資料, 展示如何使用葉編碼, 並觀察預測效果\n",
    "- 因為只有分類問題比較適合葉編碼, 因此範例與作業都使用鐵達尼的資料(二元分類問題)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做完特徵工程前的所有準備\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 因為擬合(fit)與編碼(transform)需要分開, 因此不使用.get_dummy, 而採用 sklearn 的 OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "data_path = 'data/'\n",
    "df = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "\n",
    "train_Y = df['Survived']\n",
    "df = df.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass      Name  Sex       Age  SibSp  Parch    Ticket      Fare  \\\n",
       "0     1.0  0.121348  1.0  0.283951  0.125    0.0  0.769118  0.014151   \n",
       "1     0.0  0.213483  0.0  0.481481  0.125    0.0  0.876471  0.139136   \n",
       "2     1.0  0.396629  0.0  0.333333  0.000    0.0  0.983824  0.015469   \n",
       "3     0.0  0.305618  0.0  0.444444  0.125    0.0  0.072059  0.103644   \n",
       "4     1.0  0.016854  1.0  0.444444  0.000    0.0  0.694118  0.015713   \n",
       "\n",
       "      Cabin  Embarked  \n",
       "0  0.000000  1.000000  \n",
       "1  0.557823  0.333333  \n",
       "2  0.000000  1.000000  \n",
       "3  0.380952  1.000000  \n",
       "4  0.000000  1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因為需要把類別型與數值型特徵都加入, 故使用最簡版的特徵工程\n",
    "LEncoder = LabelEncoder()\n",
    "MMEncoder = MinMaxScaler()\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].fillna(-1)\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = LEncoder.fit_transform(list(df[c].values))\n",
    "    df[c] = MMEncoder.fit_transform(df[c].values.reshape(-1, 1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.12134831, 1.        , ..., 0.01415106, 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.21348315, 0.        , ..., 0.13913574, 0.55782313,\n",
       "        0.33333333],\n",
       "       [1.        , 0.39662921, 0.        , ..., 0.01546857, 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [1.        , 0.46404494, 0.        , ..., 0.04577135, 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.09101124, 1.        , ..., 0.0585561 , 0.41496599,\n",
       "        0.33333333],\n",
       "       [1.        , 0.24719101, 1.        , ..., 0.01512699, 0.        ,\n",
       "        0.66666667]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = df.values\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.303712</td>\n",
       "      <td>0.065376</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>0.497836</td>\n",
       "      <td>0.062858</td>\n",
       "      <td>0.119929</td>\n",
       "      <td>0.843247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.418036</td>\n",
       "      <td>0.289162</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.220586</td>\n",
       "      <td>0.137843</td>\n",
       "      <td>0.134343</td>\n",
       "      <td>0.295369</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.259458</td>\n",
       "      <td>0.266751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233088</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495588</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.654321    0.500000    0.647587    0.303712    0.065376    0.063599   \n",
       "std      0.418036    0.289162    0.477990    0.220586    0.137843    0.134343   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.500000    0.250000    0.000000    0.086420    0.000000    0.000000   \n",
       "50%      1.000000    0.500000    1.000000    0.308642    0.000000    0.000000   \n",
       "75%      1.000000    0.750000    1.000000    0.444444    0.125000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "                6           7           8           9  \n",
       "count  891.000000  891.000000  891.000000  891.000000  \n",
       "mean     0.497836    0.062858    0.119929    0.843247  \n",
       "std      0.295369    0.096995    0.259458    0.266751  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.233088    0.015440    0.000000    0.666667  \n",
       "50%      0.495588    0.028213    0.000000    1.000000  \n",
       "75%      0.763971    0.060508    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_X).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## sklearn.model_selection.train_test_split(*arrays, **options)\n",
    "\n",
    "Split arrays or matrices into random train and test subsets\n",
    "\n",
    "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.\n",
    "\n",
    "### Parameters:\t\n",
    "#### *arrays : sequence of indexables with same length / shape[0]\n",
    "Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "\n",
    "#### test_size : float, int or None, optional (default=0.25)\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if train_size is unspecified, otherwise it will complement the specified train_size.\n",
    "\n",
    "#### train_size : float, int, or None, (default=None)\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "#### random_state : int, RandomState instance or None, optional (default=None)\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "#### shuffle : boolean, optional (default=True)\n",
    "Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
    "\n",
    "#### stratify : array-like or None (default=None)\n",
    "If not None, data is split in a stratified fashion, using this as the class labels.\n",
    "\n",
    "### Returns:\t\n",
    "#### splitting : list, length=2 * len(arrays)\n",
    "List containing train-test split of inputs.\n",
    "\n",
    "New in version 0.16: If the input is sparse, the output will be a scipy.sparse.csr_matrix. Else, output type is the same as the input type.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape=(445, 10), test_X=(446, 10), train_Y=(445,), test_Y=(446,)\n",
      "train_X.shape=(222, 10), val_X=(223, 10), train_Y=(222,), val_Y=(223,)\n"
     ]
    }
   ],
   "source": [
    "# 因為訓練邏輯斯迴歸時也要資料, 因此將訓練及切成三部分 train / val / test, 採用 test 驗證而非 k-fold 交叉驗證\n",
    "# train 用來訓練梯度提升樹, val 用來訓練邏輯斯迴歸, test 驗證效果\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.5)\n",
    "\n",
    "print(f'train_X.shape={train_X.shape}, test_X={test_X.shape}, train_Y={train_Y.shape}, test_Y={test_Y.shape}')\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.5)\n",
    "\n",
    "print(f'train_X.shape={train_X.shape}, val_X={val_X.shape}, train_Y={train_Y.shape}, val_Y={val_Y.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "### apply(X)\n",
    "Apply trees in the ensemble to X, return leaf indices.\n",
    "\n",
    "New in version 0.17.\n",
    "\n",
    "### Parameters:\t\n",
    "#### X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted to a sparse csr_matrix.\n",
    "\n",
    "### Returns:\t\n",
    "#### X_leaves : array-like, shape (n_samples, n_estimators, n_classes)\n",
    "For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator. In the case of binary classification n_classes is 1.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdbt.apply(train_X).shape=(222, 320, 1)\n",
      "gdbt.apply(train_X)[:, :, 0].shape=(222, 320)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., ..., 3., 4., 2.],\n",
       "       [1., 1., 2., ..., 4., 2., 1.],\n",
       "       [1., 1., 2., ..., 3., 4., 2.],\n",
       "       ...,\n",
       "       [2., 2., 1., ..., 4., 3., 1.],\n",
       "       [2., 2., 2., ..., 3., 3., 2.],\n",
       "       [2., 1., 2., ..., 4., 4., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 梯度提升樹調整參數並擬合後, 再將葉編碼 (*.apply) 結果做獨熱 / 邏輯斯迴歸\n",
    "# 調整參數的方式採用 RandomSearchCV 或 GridSearchCV, 以後的進度會再教給大家, 本次先直接使用調參結果\n",
    "gdbt = GradientBoostingClassifier(subsample=0.93, n_estimators=320, min_samples_split=0.1, min_samples_leaf=0.3, \n",
    "                                  max_features=4, max_depth=4, learning_rate=0.16)\n",
    "\n",
    "# Note: 先用 GDBT 來做 fit / regression, 得到 tree \n",
    "gdbt.fit(train_X, train_Y)\n",
    "\n",
    "print(f'gdbt.apply(train_X).shape={gdbt.apply(train_X).shape}')\n",
    "gdbt.apply(train_X)\n",
    "\n",
    "print(f'gdbt.apply(train_X)[:, :, 0].shape={gdbt.apply(train_X)[:, :, 0].shape}')\n",
    "gdbt.apply(train_X)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdbt.apply(train_X)[0, :, 0].shape=(320,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       2., 2., 2., 4., 2., 2., 2., 1., 2., 1., 2., 1., 0., 2., 4., 2., 2.,\n",
       "       1., 2., 2., 1., 1., 2., 3., 1., 2., 2., 2., 3., 1., 4., 1., 2., 2.,\n",
       "       2., 1., 2., 2., 1., 2., 3., 2., 2., 2., 2., 1., 2., 1., 2., 2., 2.,\n",
       "       2., 1., 3., 4., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       2., 1., 1., 4., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 1., 2.,\n",
       "       2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2.,\n",
       "       1., 2., 2., 2., 3., 2., 1., 3., 2., 1., 1., 2., 2., 2., 2., 1., 2.,\n",
       "       1., 2., 2., 2., 2., 2., 3., 2., 1., 2., 2., 1., 4., 2., 4., 1., 1.,\n",
       "       1., 2., 2., 2., 1., 2., 2., 3., 1., 2., 2., 2., 2., 1., 2., 4., 1.,\n",
       "       1., 2., 1., 1., 2., 2., 1., 2., 3., 1., 4., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 1., 2., 1., 2., 2., 2., 4., 0., 2., 2.,\n",
       "       2., 2., 2., 1., 2., 2., 2., 1., 1., 3., 1., 1., 2., 2., 2., 1., 2.,\n",
       "       1., 2., 1., 1., 2., 2., 1., 1., 1., 3., 2., 2., 2., 2., 4., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2., 2., 3., 1., 1.,\n",
       "       1., 1., 1., 1., 4., 1., 1., 1., 2., 2., 2., 2., 4., 2., 2., 2., 4.,\n",
       "       2., 2., 1., 1., 2., 2., 2., 2., 2., 1., 3., 2., 2., 1., 1., 1., 1.,\n",
       "       2., 1., 4., 2., 3., 2., 1., 2., 4., 3., 2., 2., 4., 2., 1., 2., 2.,\n",
       "       1., 4., 1., 1., 2., 1., 2., 2., 4., 1., 1., 3., 4., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'gdbt.apply(train_X)[0, :, 0].shape={gdbt.apply(train_X)[0, :, 0].shape}')\n",
    "gdbt.apply(train_X)[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-13e87bfb0b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Note: 顯示 leaf 值的種類\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 275\u001b[1;33m                                        raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m   4163\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Note: 顯示 leaf 值的種類\n",
    "pd.Series(gdbt.apply(train_X)[:, :, 0]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.n_values_.shape=(320,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function n_values_ is deprecated; The ``n_values_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function n_values_ is deprecated; The ``n_values_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 1, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3,\n",
       "       3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 5, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 5, 3, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 5, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 5,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 5, 3, 3, 3, 5, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 5, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 5, 5, 3, 3, 5, 5, 3, 3, 3, 3, 5,\n",
       "       3, 3, 3, 3, 3, 3, 5, 3, 3, 5, 5, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "onehot = OneHotEncoder()\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Note: 先用 OneHot Encoder 來 Encode GDBT 的 Leaf\n",
    "enc = onehot.fit(gdbt.apply(train_X)[:, :, 0])\n",
    "\n",
    "print(f'enc.n_values_.shape={enc.n_values_.shape}')\n",
    "\n",
    "\"\"\"\n",
    "enc.n_values_\n",
    "# array([3, 4])\n",
    "\n",
    "表示 ndata[0] 有 3 種特徵值\n",
    "ndata[1] 有 4 種特徵值，分別為 0,1,2,3\n",
    "\"\"\"\n",
    "enc.n_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erwin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function feature_indices_ is deprecated; The ``feature_indices_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    3,    6,    9,   12,   15,   18,   21,   24,   27,   30,\n",
       "         33,   36,   39,   42,   45,   48,   51,   54,   57,   60,   65,\n",
       "         68,   71,   74,   77,   80,   83,   86,   89,   90,   93,   98,\n",
       "        101,  104,  107,  110,  113,  116,  119,  122,  127,  130,  133,\n",
       "        136,  139,  144,  147,  152,  155,  158,  161,  164,  167,  170,\n",
       "        173,  176,  179,  184,  187,  190,  193,  196,  199,  202,  205,\n",
       "        208,  211,  214,  217,  220,  225,  230,  233,  236,  239,  242,\n",
       "        245,  248,  251,  254,  257,  260,  263,  266,  269,  272,  275,\n",
       "        278,  283,  286,  289,  292,  295,  300,  303,  306,  309,  312,\n",
       "        315,  318,  321,  324,  327,  330,  333,  336,  339,  342,  345,\n",
       "        348,  351,  354,  357,  360,  363,  366,  369,  372,  375,  378,\n",
       "        381,  384,  387,  392,  395,  398,  403,  406,  409,  412,  415,\n",
       "        418,  421,  424,  427,  430,  433,  436,  439,  442,  445,  448,\n",
       "        453,  456,  459,  462,  465,  468,  473,  476,  481,  484,  487,\n",
       "        490,  493,  496,  499,  502,  505,  508,  513,  516,  519,  522,\n",
       "        525,  528,  531,  534,  539,  542,  545,  548,  551,  554,  557,\n",
       "        560,  563,  566,  571,  574,  579,  582,  585,  588,  591,  596,\n",
       "        599,  602,  605,  608,  611,  614,  617,  620,  623,  626,  629,\n",
       "        632,  637,  642,  647,  648,  651,  654,  657,  660,  663,  666,\n",
       "        669,  672,  675,  678,  681,  686,  689,  692,  695,  698,  701,\n",
       "        706,  709,  712,  715,  718,  721,  724,  727,  730,  733,  736,\n",
       "        741,  744,  747,  750,  753,  758,  761,  764,  767,  772,  775,\n",
       "        778,  781,  784,  787,  790,  793,  796,  799,  802,  805,  808,\n",
       "        813,  816,  819,  822,  825,  828,  831,  836,  839,  842,  845,\n",
       "        848,  851,  854,  857,  862,  865,  868,  871,  876,  879,  882,\n",
       "        885,  888,  891,  894,  897,  900,  903,  906,  911,  914,  917,\n",
       "        920,  923,  926,  929,  932,  935,  940,  943,  948,  951,  954,\n",
       "        957,  962,  967,  970,  973,  978,  983,  986,  989,  992,  995,\n",
       "       1000, 1003, 1006, 1009, 1012, 1015, 1018, 1023, 1026, 1029, 1034,\n",
       "       1039, 1042], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "enc.feature_indices_\n",
    "# array([0, 3, 7])\n",
    "表示特徵的範圍，例如\n",
    "0-3 為 ndata[0],\n",
    "3-7 為 ndata[1]\n",
    "\"\"\"\n",
    "enc.feature_indices_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: 然後再用 Logistic Regression 來 fit OneHot Encoder 的結果\n",
    "lr.fit(onehot.transform(gdbt.apply(val_X)[:, :, 0]), val_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "##  首先看一下 roc_curve 的定义：\n",
    "\n",
    "ROC曲线的全称是“受试者工作特性”曲线（Receiver Operating Characteristic），源于二战中用于敌机检测的雷达信号分析技术。是反映敏感性和特异性的综合指标。它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大，判别的准确性越高。在ROC曲线上，最靠近坐标图左上方的点为敏感性和特异性均较高的临界值。\n",
    "\n",
    "## sklearn.metrics.roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
    "\n",
    "Compute Receiver operating characteristic (ROC)\n",
    "\n",
    "Note: this implementation is restricted to the binary classification task.\n",
    "\n",
    "### Parameters:\t\n",
    "#### y_true : array, shape = [n_samples]\n",
    "True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.\n",
    "\n",
    "#### y_score : array, shape = [n_samples]\n",
    "Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by “decision_function” on some classifiers).\n",
    "\n",
    "#### pos_label : int or str, default=None\n",
    "Label considered as positive and others are considered negative.\n",
    "\n",
    "#### sample_weight : array-like of shape = [n_samples], optional\n",
    "Sample weights.\n",
    "\n",
    "#### drop_intermediate : boolean, optional (default=True)\n",
    "Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.\n",
    "\n",
    "New in version 0.17: parameter drop_intermediate.\n",
    "\n",
    "### Returns:\t\n",
    "#### fpr : array, shape = [>2]\n",
    "Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i].\n",
    "\n",
    "#### tpr : array, shape = [>2]\n",
    "Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "\n",
    "#### thresholds : array, shape = [n_thresholds]\n",
    "Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將梯度提升樹+葉編碼+邏輯斯迴歸結果輸出\n",
    "pred_gdbt_lr = lr.predict_proba(   onehot.transform(gdbt.apply(test_X)[:, :, 0])   )[:, 1]\n",
    "fpr_gdbt_lr, tpr_gdbt_lr, _ = roc_curve(test_Y, pred_gdbt_lr)\n",
    "\n",
    "# 將只用梯度提升樹結果輸出\n",
    "pred_gdbt = gdbt.predict_proba(test_X)[:, 1]\n",
    "fpr_gdbt, tpr_gdbt, _ = roc_curve(test_Y, pred_gdbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 將結果繪圖\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_gdbt, tpr_gdbt, label='GDBT')\n",
    "plt.plot(fpr_gdbt_lr, tpr_gdbt_lr, label='GDBT + LR')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業1\n",
    "* 請對照範例，完成隨機森林的鐵達尼生存率預測，以及對應的葉編碼+邏輯斯迴歸\n",
    "\n",
    "# 作業2\n",
    "* 上述的結果，葉編碼是否有提高預測的正確性呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
