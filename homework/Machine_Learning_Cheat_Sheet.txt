
* SVM
支撐向量機(support vector machine, SVM)

* CART: 

* k-NN 分類器:  k-Nearest Neighbors 

------

# Day 36
	* 評估指標 - 回歸
		* MAE, Mean Absolute Error, 範圍: [-∞, ∞]
		* MSE, Mean Square Error, 範圍: [-∞, ∞]
		* R-square, 範圍: [0, 1]
	* 評估指標 - 分類
		* AUC, Area Under Curve, 範圍: [0, 1]
			* The curve is : 接收者操作特徵曲線（receiver operating characteristic curve，或者叫ROC曲線）
		* F1-Score
			* F1-Score 則是 Precision, Recall 的調和平均數
			* Precision: 模型判定瑕疵，樣本確實為瑕疵的比例例
				* Precision = TP / (TP + FP)
			* Recall: 模型判定的瑕疵，佔樣本所有瑕疵的比例例
				* Recall = TP / (TP + FN)
			* Definitions
				* 真陽性 (TP, true positive)
					* 正確的肯定。又稱：命中 (hit)
				* 真陰性 (TN, true negative)
					* 正確的否定。又稱：正確拒絕 (correct rejection)
				* 偽陽性 (FP, false positive)
					* 錯誤的肯定，又稱：假警報 (false alarm)，第一型錯誤
				* 偽陰性 (FN, false negative)
					* 錯誤的否定，又稱：未命中 (miss)，第二型錯誤
	* 混淆矩陣 (Confusion Matrix) ?
	* Q: 這麼多評估指標，該怎麼選擇?
		* 回歸問題: 可以透過 R-square 很快了了解預測的準確程度；
		* 分類問題: 若若為二分類 (binary classification)，通常使用 AUC 評估。
			* 但如果有特別希望哪一類別不要分錯，則可使⽤用 F1-Score，觀察 Recall 值或是 Precision 值。
		* 多分類問題: 則可使用 top-k accuracy，k 代表模型預測前 k 個類別有包含正確類別即為正確 (ImageNet 競賽通常都是比 Top-5 Accuracy)
		
		
------

# Day 37 Regression 模型

	* 把 LogisticRegression 訓練出來的結果視覺化
```
	lr = LogisticRegression
	lr.fit(X_train_std, y_train['target'].values)
	
	plot_decision_regions(X_train_std, y_train['target'], classifier=lr)
	plt.xlabel('...')
	plt.ylabel('...')
	plt.show()
```

	* Logistic Regression優點：
		* 資料不需要線性可分
		* 可以獲得A類跟B類的機率
		* 實務上Logistic Regression執行速度非常快
		
	* Logistic Regression缺點：
		* 線的切法不夠漂亮，以人的觀察應該要大概要像是綠色的線才是一個比較好的分法（下一章的SVM將會解決這個問題）





------

# Day 41

	* 吉尼係數 (gini-index) 或熵 (entropy)
		* 0 => 1 
			* 1 - (1/2)**2 = 1/2  
			
	* 混亂程度有兩種評估方式：
		一、 Gini impurity ：各個類別的數據比例，兩兩相乘（不乘自身），總和越小越好；
		二、 information gain ：各個類別的數據比例，求熵，總和越小越好。
		
	* Decision Tree
		* 把區隔效果 (Information Gain) 最好的放在跟目錄
		* 以公司要不要錄取來說, 考試是不是及格, 就是最大的因素 (以我個人來說). 如果考 0 分, 100% 不錄取
		* 以要不要處理 email, 收件者有提到我的名字的, 就優先處理
		
	
------

# Day 42

## 建立模型四步驟

	* 在 Scikit-learn 中，建立一個機器學習的模型其實非常簡單，流程大略是以下四個步驟

	* 讀進資料，並檢查資料的 shape (有多少 samples (rows), 多少 features (columns)，label 的型態是什麼？)
		* 使用 pandas 讀取 .csv 檔：pd.read_csv
		* 使用 numpy 讀取 .txt 檔：np.loadtxt
		* 使用 Scikit-learn 內建的資料集：sklearn.datasets.load_xxx
		* 檢查資料數量：data.shape (data should be np.array or dataframe)
		
	* 將資料切為訓練 (train) / 測試 (test)
		* train_test_split(data)
		
	* 建立模型，將資料 fit 進模型開始訓練
		* clf = DecisionTreeClassifier()
		* clf.fit(x_train, y_train)
		
	* 將測試資料 (features) 放進訓練好的模型中，得到 prediction，與測試資料的 label (y_test) 做評估
		* clf.predict(x_test)
		* accuracy_score(y_test, y_pred)
		* f1_score(y_test, y_pred)
	
	* print(iris.feature_names)
	* print("Feature importance: ", clf.feature_importances_)
	
------

# Day 43

	* One of 整體學習（Ensemble learning）
		* 可以將數個分類器的預測結果綜合考慮，藉此達到顯著提升分類效果

	* Bootstrap Aggregating


------

# Day 44

	------

	 ## sklearn.ensemble.RandomForestClassifier
	```
	class sklearn.ensemble.RandomForestClassifier(n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)[source]
	```
	A random forest classifier.

	A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).

	Read more in the User Guide.

	### Parameters:	
	#### n_estimators : integer, optional (default=10)
	The number of trees in the forest.

	Changed in version 0.20: The default value of n_estimators will change from 10 in version 0.20 to 100 in version 0.22.

	#### criterion : string, optional (default=”gini”)
	The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.

	#### max_depth : integer or None, optional (default=None)
	The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

	#### min_samples_split : int, float, optional (default=2)
	The minimum number of samples required to split an internal node:

	If int, then consider min_samples_split as the minimum number.
	If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.
	Changed in version 0.18: Added float values for fractions.

	#### min_samples_leaf : int, float, optional (default=1)
	The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

	If int, then consider min_samples_leaf as the minimum number.
	If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.
	Changed in version 0.18: Added float values for fractions.

	#### min_weight_fraction_leaf : float, optional (default=0.)
	The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

	#### max_features : int, float, string or None, optional (default=”auto”)
	The number of features to consider when looking for the best split:

	If int, then consider max_features features at each split.
	If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.
	If “auto”, then max_features=sqrt(n_features).
	If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).
	If “log2”, then max_features=log2(n_features).
	If None, then max_features=n_features.
	Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

	#### max_leaf_nodes : int or None, optional (default=None)
	Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

	#### min_impurity_decrease : float, optional (default=0.)
	A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

	The weighted impurity decrease equation is the following:

	N_t / N * (impurity - N_t_R / N_t * right_impurity
						- N_t_L / N_t * left_impurity)
	where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

	N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

	New in version 0.19.

	#### min_impurity_split : float, (default=1e-7)
	Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.

	Deprecated since version 0.19: min_impurity_split has been deprecated in favor of min_impurity_decrease in 0.19. The default value of min_impurity_split will change from 1e-7 to 0 in 0.23 and it will be removed in 0.25. Use min_impurity_decrease instead.
	#### bootstrap : boolean, optional (default=True)
	Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.

	#### oob_score : bool (default=False)
	Whether to use out-of-bag samples to estimate the generalization accuracy.

	#### n_jobs : int or None, optional (default=None)
	The number of jobs to run in parallel for both fit and predict. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

	#### random_state : int, RandomState instance or None, optional (default=None)
	If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.

	#### verbose : int, optional (default=0)
	Controls the verbosity when fitting and predicting.

	#### warm_start : bool, optional (default=False)
	When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See the Glossary.

	#### class_weight : dict, list of dicts, “balanced”, “balanced_subsample” or None, optional (default=None)
	Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.

	Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].

	The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))

	The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.

	For multi-output, the weights of each column of y will be multiplied.

	Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

	### Attributes:	
	#### estimators_ : list of DecisionTreeClassifier
	The collection of fitted sub-estimators.

	#### classes_ : array of shape = [n_classes] or a list of such arrays
	The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).

	#### n_classes_ : int or list
	The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).

	#### n_features_ : int
	The number of features when fit is performed.

	#### n_outputs_ : int
	The number of outputs when fit is performed.

	#### feature_importances_ : array of shape = [n_features]
	Return the feature importances (the higher, the more important the feature).

	#### oob_score_ : float
	Score of the training dataset obtained using an out-of-bag estimate.

	#### oob_decision_function_ : array of shape = [n_samples, n_classes]
	Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN.

	------

	=============


	-------

	## sklearn.ensemble.RandomForestRegressor
	```
	class sklearn.ensemble.RandomForestRegressor(n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)[source]
	A random forest regressor.
	```

	A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).

	Read more in the User Guide.

	### Parameters:	
	#### n_estimators : integer, optional (default=10)
	The number of trees in the forest.

	Changed in version 0.20: The default value of n_estimators will change from 10 in version 0.20 to 100 in version 0.22.

	#### criterion : string, optional (default=”mse”)
	The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion, and “mae” for the mean absolute error.

	New in version 0.18: Mean Absolute Error (MAE) criterion.

	#### max_depth : integer or None, optional (default=None)
	The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

	#### min_samples_split : int, float, optional (default=2)
	The minimum number of samples required to split an internal node:

	If int, then consider min_samples_split as the minimum number.
	If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.
	Changed in version 0.18: Added float values for fractions.

	min_samples_leaf : int, float, optional (default=1)
	The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

	If int, then consider min_samples_leaf as the minimum number.
	If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.
	Changed in version 0.18: Added float values for fractions.

	#### min_weight_fraction_leaf : float, optional (default=0.)
	The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

	#### max_features : int, float, string or None, optional (default=”auto”)
	The number of features to consider when looking for the best split:

	If int, then consider max_features features at each split.
	If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.
	If “auto”, then max_features=n_features.
	If “sqrt”, then max_features=sqrt(n_features).
	If “log2”, then max_features=log2(n_features).
	If None, then max_features=n_features.
	Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

	#### max_leaf_nodes : int or None, optional (default=None)
	Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

	#### min_impurity_decrease : float, optional (default=0.)
	A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

	The weighted impurity decrease equation is the following:

	N_t / N * (impurity - N_t_R / N_t * right_impurity
						- N_t_L / N_t * left_impurity)
	where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

	N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

	New in version 0.19.

	#### min_impurity_split : float, (default=1e-7)
	Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.

	Deprecated since version 0.19: min_impurity_split has been deprecated in favor of min_impurity_decrease in 0.19. The default value of min_impurity_split will change from 1e-7 to 0 in 0.23 and it will be removed in 0.25. Use min_impurity_decrease instead.
	bootstrap : boolean, optional (default=True)
	Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.

	#### oob_score : bool, optional (default=False)
	whether to use out-of-bag samples to estimate the R^2 on unseen data.

	#### n_jobs : int or None, optional (default=None)
	The number of jobs to run in parallel for both fit and predict. None` means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.`

	#### random_state : int, RandomState instance or None, optional (default=None)
	If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.

	#### verbose : int, optional (default=0)
	Controls the verbosity when fitting and predicting.

	#### warm_start : bool, optional (default=False)
	When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See the Glossary.

	### Attributes:	
	#### estimators_ : list of DecisionTreeRegressor
	The collection of fitted sub-estimators.

	#### feature_importances_ : array of shape = [n_features]
	Return the feature importances (the higher, the more important the feature).

	#### n_features_ : int
	The number of features when fit is performed.

	#### n_outputs_ : int
	The number of outputs when fit is performed.

	#### oob_score_ : float
	Score of the training dataset obtained using an out-of-bag estimate.

	#### oob_prediction_ : array of shape = [n_samples]
	Prediction computed with out-of-bag estimate on the training set.

	-------



	from sklearn import datasets, metrics
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.ensemble import RandomForestRegressor
	from sklearn.model_selection import train_test_split
	
	class RandomForestClassifierEvaluator():
		def __init__(self, n_estimators='warn', criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None):
			
			# 建立模型
			self.clf = RandomForestClassifier(n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split)
		
		def run(self, dataset):

			# 切分訓練集/測試集
			x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=4)


			# 訓練模型
			self.clf.fit(x_train, y_train)

			# 預測測試集
			y_pred = self.clf.predict(x_test)

			acc = metrics.accuracy_score(y_test, y_pred)

			print("Acuuracy: ", acc)

			if 'feature_names' in dataset:
			
				print(dataset.feature_names)
				print("Feature importance: ", self.clf.feature_importances_)
			
	# 讀取鳶尾花資料集
	iris = datasets.load_iris()
	evaluator = RandomForestClassifierEvaluator()
	evaluator.run(iris)
			
	from sklearn.metrics import mean_squared_error
	from sklearn.metrics import mean_absolute_error
	
	class RandomForestRegressorEvaluator():
		def __init__(self, n_estimators='warn', criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False):

			# 建立模型
			self.clf = RandomForestRegressor(n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, bootstrap, oob_score, n_jobs, random_state, verbose, warm_start)
			self.criterion = criterion
			
		def run(self, dataset):
			# 切分訓練集/測試集
			
			x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=4)
			# 訓練模型
			self.clf.fit(x_train, y_train)

			# 預測測試集
			y_pred = self.clf.predict(x_test)

			if self.criterion == 'mae':
				# 預測值與實際值的差距，使用 MAE
				print("\033[1;33m Mean absolute error: %.2f \033[0m" % mean_absolute_error(y_test, y_pred))
			else:
				# 預測值與實際值的差距，使用 MSE
				print("\033[1;33m Mean squared error: %.2f \033[0m" % mean_squared_error(y_test, y_pred))
			
			if 'feature_names' in dataset:
			
				print(dataset.feature_names)
				print("Feature importance: ", self.clf.feature_importances_)
			
	# 讀取 Boston 資料集
	boston = datasets.load_boston()
	evaluator = RandomForestRegressorEvaluator()
	evaluator.run(boston)



# Day 45

	* Ensemble: Gradient Boosting vs. Bagging (Bootstrap Aggregating)
	
	* Bias vs. Variance trade-off
		* Linear model had a higher bias
		* Polynomial model, depends a lot on the choice of training data. 
		* If you change the data slightly, the shape of the curve will look very different, and the error will swing widely. 
		* Therefore, the model is said to have high variance.
		
	* Bias: evaluating under-fitting
	* Variance: evaluating over-fitting
	
	* Bagging:
		* Use Average or Voting to reduce variance to avoid over-fitting
			* Use Average: in Regression problem
			* Use Voting: in Classification problem
			
	* Out of Bag : evaluating error of data out of bag
	
	* Bagging is used with "Strong Models": Use averaging or voting to avoid over-fitting caused by strong models
	* Boosting is used with "Weak Models"
	
	* GBDT(Gradient Boosting Decision Tree) 又叫 MART(Multiple Additive Regression Tree)，
		* 是一種迭代的決策樹算法，該算法由多棵決策樹組成，所有樹的結論累加起來做最終答案。
		* 它在被提出之初就和SVM一起被認為是泛化能力較強的算法。

	* GBDT中的樹是回歸樹(不是分類樹)，GBDT用來做回歸預測，調整後也可以用于分類。
	
	* Bagging算法是這樣做的︰每個分類器都隨機從原樣本中做有放回的采樣，然後分別在這些采樣後的樣本上訓練分類器，然後再把這些分類器組合起來。
		* 簡單的多數投票一般就可以。
		* 其代表算法是隨機森林。
	* Boosting的意思是這樣，他通過迭代地訓練一系列的分類器，每個分類器采用的樣本分布都和上一輪的學習結果有關。其代表算法是AdaBoost, GBDT。
	
	* 對于Bagging算法來說，由于我們會並行地訓練很多不同的分類器的目的就是降低這個方差(variance) ,
		* 因為采用了相互獨立的基分類器多了以後，h的值自然就會靠近.所以對于每個基分類器來說，
		* 目標就是如何降低這個偏差(bias),所以我們會采用深度很深甚至不剪枝的決策樹。

	* 對于Boosting來說，每一步我們都會在上一輪的基礎上更加擬合原資料，所以可以保證偏差(bias),
		* 所以對于每個基分類器來說，問題就在于如何選擇variance更小的分類器，即更簡單的分類器，所以我們選擇了深度很淺的決策樹。
		
	* Erwin: 
		* Bagging 是用一堆 over-fitting 的 tree (深度很深)來組合, 避免 over-fitting ?
		* Boosting 是用一堆 under-fitting 的 tree (深度很深)來組合, 避免 under-fitting ?
			* 迭代 (iteration) 多棵回歸樹來共同決策
		
	* xgboost 的全稱是eXtreme Gradient Boosting，它是Gradient Boosting Machine的一個c++實現，作者為正在華盛頓大學研究機器學習的大牛陳天奇 。
		* xgboost，在計算速度和準確率上，較GBDT有明顯的提升。
		* xgboost最大的特點在于，它能夠自動利用CPU的多線程進行並行，同時在算法上加以改進提高了精度。
		* 它的處女秀是Kaggle的 希格斯子信號識別競賽，因為出眾的效率與較高的預測準確度在比賽論壇中引起了參賽選手的廣泛關注。
		

# Day 46

	* Sample codes
		from sklearn.ensemble import GradientBoostingRegressor
		from sklearn.ensemble import GradientBoostingClassifier
		
		clf = GradientBoostingClassifier(
			loss="deviance", #Loss 的選擇，若若改為 exponential 則會變成
			Adaboosting 演算法，概念念相同但實作稍微不同
			learning_rate=0.1, #每棵樹對最終結果的影響，應與 n_estimators 成反比
			n_estimators=100 #決策樹的數量量
		)
		
	* Class Wrapper

		from sklearn.ensemble import GradientBoostingClassifier
		from sklearn.ensemble import GradientBoostingRegressor
		from sklearn.model_selection import train_test_split

		class GradientBoostingClassifierEvaluator():
			def __init__(self, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001):

				# 建立模型
				self.clf = GradientBoostingClassifier(loss, learning_rate, n_estimators, subsample, criterion, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_depth, min_impurity_decrease, min_impurity_split, init, random_state, max_features, verbose, max_leaf_nodes, warm_start, presort, validation_fraction, n_iter_no_change, tol)

			def run(self, dataset):

				# 切分訓練集/測試集
				x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=4)


				# 訓練模型
				self.clf.fit(x_train, y_train)

				# 預測測試集
				y_pred = self.clf.predict(x_test)

				acc = metrics.accuracy_score(y_test, y_pred)

				print("Acuuracy: ", acc)

				if 'feature_names' in dataset:
					
					print(dataset.feature_names)
					print("Feature importance: ", self.clf.feature_importances_)
					
		
		evaluator = GradientBoostingClassifierEvaluator()
		evaluator.run(digits)
		Acuuracy:  0.9644444444444444
		
# Day 47

	* Sample codes
		from sklearn import datasets, metrics
		from sklearn.model_selection import train_test_split, KFold, GridSearchCV
		from sklearn.ensemble import GradientBoostingRegressor


		# 讀取手寫辨識資料集
		digits = datasets.load_digits()
		# 切分訓練集/測試集
		x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=42)

		# 建立模型
		clf = GradientBoostingRegressor(random_state=7)

		# 先看看使用預設參數得到的結果，約為 1.41 的 MSE
		clf.fit(x_train, y_train)
		y_pred = clf.predict(x_test)
		print(metrics.mean_squared_error(y_test, y_pred))

		# 設定要訓練的超參數組合
		n_estimators = [100, 200, 300, 500, 1000, 3000, 10000]
		max_depth = [1, 3, 5, 7]

		# 建立 dictionary
		param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)

		## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)
		grid_search = GridSearchCV(clf, param_grid, scoring="neg_mean_squared_error", n_jobs=-1, verbose=1)

		# 開始搜尋最佳參數
		grid_result = grid_search.fit(x_train, y_train)

		# 印出最佳結果與最佳參數
		print("Best Accuracy: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

		# 使用最佳參數重新建立模型
		clf_bestparam = GradientBoostingRegressor(max_depth=grid_result.best_params_['max_depth'],
												   n_estimators=grid_result.best_params_['n_estimators'])

		# 訓練模型
		clf_bestparam.fit(x_train, y_train)

		# 預測測試集
		y_pred = clf_bestparam.predict(x_test)

		# 調整參數後約可降至 0.96 的 MSE
		print(metrics.mean_squared_error(y_test, y_pred))

	* But in truth even a random search of the parameter space can be MUCH more effective than a grid search!
	
	
# Day 048

	* Sample 1 GridSearchCV
	
		from sklearn.model_selection import train_test_split, KFold, GridSearchCV

		# 設定要訓練的超參數組合
		n_estimators = [10,50, 100, 200]
		max_depth = [1, 3, 5, 7, 10]

		# 建立 dictionary
		param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)

		## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)
		grid_search = GridSearchCV(clf, param_grid, scoring="f1", n_jobs=-1, verbose=1)

		# 開始搜尋最佳參數
		grid_result = grid_search.fit(x_train, y_train)

		# 印出最佳結果與最佳參數
		print("Best Accuracy: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

		# 使用最佳參數重新建立模型
		clf_bestparam = GradientBoostingClassifier(max_depth=grid_result.best_params_['max_depth'],
												   n_estimators=grid_result.best_params_['n_estimators'])

		# 訓練模型
		clf_bestparam.fit(x_train, y_train)

		# 預測測試集
		y_pred = clf_bestparam.predict(x_test)

		# 調整參數後約可降至 0.96 的 MSE
		print(metrics.mean_squared_error(y_test, y_pred))

	* Sample 2 
	
		from sklearn.model_selection import RandomizedSearchCV
		
		param_dict = {
				'n_estimators':range(10,500,4),
				'max_depth':range(2,15,1),
				'learning_rate':np.linspace(0.001, 0.01, 2, 20),
				'subsample':np.linspace(0.5, 0.95, 20)
				}



		## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)
		random_search = RandomizedSearchCV(clf, param_dict, scoring="f1", n_jobs=-1, verbose=1)

		# 開始搜尋最佳參數
		random_result = random_search.fit(x_train, y_train)

		# 印出最佳結果與最佳參數
		print("Best Accuracy: %f using %s" % (random_result.best_score_, random_result.best_params_))

		# 使用最佳參數重新建立模型
		clf_bestparam = GradientBoostingClassifier(max_depth=random_result.best_params_['max_depth'],
												   n_estimators=random_result.best_params_['n_estimators'],
												   learning_rate=random_result.best_params_['learning_rate'],
												   subsample=random_result.best_params_['subsample']
												  )

		# 訓練模型
		clf_bestparam.fit(x_train, y_train)

		# 預測測試集
		y_pred = clf_bestparam.predict(x_test)

		# 調整參數後約可降至 0.96 的 MSE
		print(metrics.mean_squared_error(y_test, y_pred))
		


# Day 054 : clustering 1 非監督式機器學習簡介

	* Unsupervised Learning 就是用來做 Clustering 
	

# Day 055 : clustering 2 聚類算法

	* Differences:
		* 監督式學習 目標在於找出決策邊界(decision boundary)
		* Clustering 目標在於找出資料結構(關聯性)
	
	* K-means 聚類算法
		* 把所有資料點分成 k 個 cluster，使得相同 cluster 中的所有資料點彼此儘量量相似，而不同 cluster 的資料點儘量量不同。
		* 距離測量量（e.g. 歐氏距離）用於計算資料點的相似度和相異異度。每個 cluster 有一個中心點。中心點可理理解為最能代表 cluster 的點。
		* K-means 目標是使總體群內平方誤差 (其他點與 Centroid 的距離) 最小
		
	* K-means 注意事項
		* Random initialization: initial 設定的不同，會導致得到不同 clustering 的結果，可能導致 local optima，⽽而非 global optima。
		* 因爲沒有預先的標記，對於 cluster 數量量多少才是最佳解，沒有標準答案，得靠手動測試觀察。
			* 盡可能把資料 Visualize ?
		* 
		
	* Ground True
		* In machine learning, the term "ground truth" refers to the accuracy of the training set's classification 
		* for supervised learning techniques
		
	* Sample codes
		import matplotlib
		import matplotlib.pyplot as plt
		# Though the following import is not directly being used, it is required
		# for 3D projection to work
		from mpl_toolkits.mplot3d import Axes3D

		from sklearn.cluster import KMeans
		from sklearn import datasets
		%matplotlib inline
		
		estimators = [('k_means_8', KMeans(n_clusters=8)),
				  ('k_means_3', KMeans(n_clusters=3)),
				  ('k_means_bad_init', KMeans(n_clusters=3, n_init=10, init='random'))]
		fignum = 1
		titles = ['8 clusters', '3 clusters', '3 clusters, bad initialization']
		for name, est in estimators:
			fig = plt.figure(fignum, figsize=(8, 6))
			ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)
			
			## fit data
			## est = KMeans(....)
			est.fit(X)
			
			labels = est.labels_
			print (f'labels = {labels}')

			# scatter(xs, ys, zs=0, zdir='z', s=20, c=None, depthshade=True, *args, **kwargs)
			# Create a scatter plot
			# xs, ys : array-like. The data positions.
			#     float or array-like, optional, default: 0
			#     The z-positions. Either an array of the same length as xs and ys or a single value to place all points in the same plane.
			# c : color, sequence, or sequence of color, optional
			ax.scatter(X[:, 3], X[:, 0], X[:, 2],
					   c=labels.astype(np.float), edgecolor='k')

			#ax.w_xaxis.set_ticklabels([])
			ax.set_xlabel('x axis')
			#ax.w_yaxis.set_ticklabels([])
			ax.set_ylabel('y axis')
			#ax.w_zaxis.set_ticklabels([])
			ax.set_zlabel('z axis')
			ax.set_title(titles[fignum - 1])
			ax.dist = 12
			fignum = fignum + 1

			
# Day 056 : clustering 2 聚類算法

	* 輪輪廓分析 (Silhouette analysis)
	
	* 轮廓系数
		* 取值为[-1, 1]，其值越大越好，且当值为负时，表明 ai<bi，样本被分配到错误的簇中，聚类结果不可接受。
		* 对于接近0的结果，则表明聚类结果有重叠的情况

	* sklearn.metrics.silhouette_score(X, labels, metric=’euclidean’, sample_size=None, random_state=None, **kwds)
		* Compute the mean Silhouette Coefficient of all samples
		* Is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. 
		* The Silhouette Coefficient for a sample is (b - a) / max(a, b). 
		* To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of. 
		* Note that Silhouette Coefficient is only defined if number of labels is 2 <= n_labels <= n_samples - 1
		* The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.
		
	* 可以 draw :
		* cluster center
		* silhouette values (空間分布)
		

# Day 057 : clustering 3 階層分群算法

	* 階層式分析
		* 一種構建 cluster 的層次結構的算法。
		* 該算法從分配給自己 cluster 的所有資料點開始。
		* 然後，兩兩個距離最近的 cluster 合併為同一個 cluster。
		* 最後，當只剩下一個 cluster 時，該算法結束。
		
	* K-means vs. 階層分群
		* K-mean 要預先定義群數 (n of clusters)
		* 階層分群可根據定義距離來來分群(bottom-up)，也可以決定羣數做分羣 (top-down)
		
	* 階層分群演算法流程
		* 不指定分群的數量量
			• 每筆資料為一個 cluster
			• 計算每兩兩群之間的距離
			• 將最近的兩兩群合併成一群
			• 重覆步驟 2、3，直到所有資料合併成同一 cluster
			
	* 階層分群距離計算方式 : single-link
		* 群聚與群聚間的距離可以定義為不同群聚中最接近兩兩點間的距離
		
	* 階層分群距離計算方式 : complete-link
		* 群聚間的距離定義為不同群聚中最遠兩兩點間的距離，這樣可以保證這兩兩個集合合併後, 任何一對的距離不會大於 d。
		
	* 階層分群距離計算方式 : average-link
		* 群聚間的距離定義為不同群聚間各點與各點間距離總和的平均。
		
	* 階層分群優劣分析
		* 優點
			1. 概念簡單，易於呈現
			2. 不需指定群數
		* 缺點
			* 只適用於少量資料，大量資料會很難處理
			
	* 結論
		* 階層式分群在無需定義群數的情況下做資料的分群，而後可以用不同的距離定義方式決定資料群組。
		* 分群距離計算方式有 single-link, complete-link, average-link。
		* 概念簡單且容易呈現，但不適合用在大資料。
		
	